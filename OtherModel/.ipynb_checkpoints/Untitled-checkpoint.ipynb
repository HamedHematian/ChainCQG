{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import T5Tokenizer, BartTokenizer, GPT2Tokenizer,BertTokenizer\n",
    "t5tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "#tokenizer.add_tokens(['<sep>', '<hl>'])\n",
    "barttokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "barttokenizer_large = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "gpttoeknizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "berttokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barttokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "barttokenizer_large = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:2;3:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinggu/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-870e78efe28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpttoeknizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pad_toeee'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'[PAD]'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36madd_special_tokens\u001b[0;34m(self, special_tokens_dict)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0madded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspecial_tokens_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECIAL_TOKENS_ATTRIBUTES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50257]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpttoeknizer.encode(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer.vocab_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.bos_token = \"<s>\"\n",
    "print(t5tokenizer.bos_token)\n",
    "handle_special_token(t5tokenizer, None)\n",
    "print(t5tokenizer.bos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in gpttoeknizer.get_vocab():\n",
    "    print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer.add_special_tokens({\"sep_token\": \"<sep>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpttoeknizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for one in barttokenizer.get_vocab():\n",
    "    #print(one)\n",
    "    pass\n",
    "print(barttokenizer.bos_token)\n",
    "print(barttokenizer.eos_token)\n",
    "print(barttokenizer.sep_token)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in t5tokenizer.get_vocab():\n",
    "    #print(one)\n",
    "    pass\n",
    "print(t5tokenizer.bos_token)\n",
    "print(t5tokenizer.eos_token)\n",
    "print(t5tokenizer.sep_token)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer.bos_token = \"<s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer.get_vocab()[\"<s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpttoeknizer.bos_token)\n",
    "print(gpttoeknizer.eos_token)\n",
    "print(gpttoeknizer.sep_token)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in gpttoeknizer.get_vocab():\n",
    "    print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(barttokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(barttokenizer_large.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = barttokenizer_large.get_vocab()\n",
    "barttokenizer.get_vocab() == a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "t5tokenizer_large = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "barttokenizer.get_vocab() == barttokenizer_large.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep = \"<\\sep>\"\n",
    "t5tokenizer.add_tokens([sep])\n",
    "# t5tokenizer.add_special_tokens([sep])\n",
    "t5tokenizer.get_vocab()[sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barttokenizer.add_tokens([sep])\n",
    "barttokenizer.get_vocab()[sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpttoeknizer.add_tokens([sep])\n",
    "gpttoeknizer.get_vocab()[sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berttokenizer.add_tokens([sep])\n",
    "berttokenizer.get_vocab()[sep]\n",
    "# for one in berttokenizer.get_vocab():\n",
    "#     print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hidden-states of the model at the output of each layer plus the initial embedding outputs.\"\n",
    "c_text = \"Hidden-states of the model at the output of each     <\\sep>layer plus the initial embedding outputs.\"\n",
    "d_text = \"Hidden-states of the model at the output of each<\\sep>layer plus the initial embedding outputs.\"\n",
    "s_text = \"Hidden-states of the model at the output of each <\\sep>     layer plus the initial embedding outputs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 19595, 118, 2231, 1104, 1103, 2235, 1120, 1103, 5964, 1104, 1296, 6440, 4882, 1103, 3288, 9712, 4774, 3408, 5964, 1116, 119, 102]\n",
      "[101, 19595, 118, 2231, 1104, 1103, 2235, 1120, 1103, 5964, 1104, 1296, 28996, 6440, 4882, 1103, 3288, 9712, 4774, 3408, 5964, 1116, 119, 102]\n",
      "[101, 19595, 118, 2231, 1104, 1103, 2235, 1120, 1103, 5964, 1104, 1296, 28996, 6440, 4882, 1103, 3288, 9712, 4774, 3408, 5964, 1116, 119, 102]\n",
      "[101, 19595, 118, 2231, 1104, 1103, 2235, 1120, 1103, 5964, 1104, 1296, 28996, 6440, 4882, 1103, 3288, 9712, 4774, 3408, 5964, 1116, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "print(berttokenizer.encode(text))\n",
    "print(berttokenizer.encode(c_text))\n",
    "print(berttokenizer.encode(d_text))\n",
    "print(berttokenizer.encode(s_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27194, 18, 5540, 7, 13, 8, 825, 44, 8, 3911, 13, 284, 3760, 303, 8, 2332, 25078, 26, 53, 3911, 7, 5]\n",
      "[27194, 18, 5540, 7, 13, 8, 825, 44, 8, 3911, 13, 284, 32100, 3760, 303, 8, 2332, 25078, 26, 53, 3911, 7, 5]\n",
      "[27194, 18, 5540, 7, 13, 8, 825, 44, 8, 3911, 13, 284, 32100, 3760, 303, 8, 2332, 25078, 26, 53, 3911, 7, 5]\n",
      "[27194, 18, 5540, 7, 13, 8, 825, 44, 8, 3911, 13, 284, 32100, 3760, 303, 8, 2332, 25078, 26, 53, 3911, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "print(t5tokenizer.encode(text))\n",
    "print(t5tokenizer.encode(c_text))\n",
    "print(t5tokenizer.encode(d_text))\n",
    "print(t5tokenizer.encode(s_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 43024, 12, 26947, 9, 5, 1421, 23, 5, 4195, 9, 349, 10490, 2704, 5, 2557, 33183, 11303, 39512, 4, 2]\n",
      "[0, 43024, 12, 26947, 9, 5, 1421, 23, 5, 4195, 9, 349, 50265, 39165, 2704, 5, 2557, 33183, 11303, 39512, 4, 2]\n",
      "[0, 43024, 12, 26947, 9, 5, 1421, 23, 5, 4195, 9, 349, 50265, 39165, 2704, 5, 2557, 33183, 11303, 39512, 4, 2]\n",
      "[0, 43024, 12, 26947, 9, 5, 1421, 23, 5, 4195, 9, 349, 50265, 39165, 2704, 5, 2557, 33183, 11303, 39512, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "print(barttokenizer.encode(text))\n",
    "print(barttokenizer.encode(c_text))\n",
    "print(barttokenizer.encode(d_text))\n",
    "print(barttokenizer.encode(s_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41691, 12, 27219, 286, 262, 2746, 379, 262, 5072, 286, 1123, 7679, 5556, 262, 4238, 11525, 12083, 23862, 13]\n",
      "[41691, 12, 27219, 286, 262, 2746, 379, 262, 5072, 286, 1123, 50257, 29289, 5556, 262, 4238, 11525, 12083, 23862, 13]\n",
      "[41691, 12, 27219, 286, 262, 2746, 379, 262, 5072, 286, 1123, 50257, 29289, 5556, 262, 4238, 11525, 12083, 23862, 13]\n",
      "[41691, 12, 27219, 286, 262, 2746, 379, 262, 5072, 286, 1123, 50257, 29289, 5556, 262, 4238, 11525, 12083, 23862, 13]\n"
     ]
    }
   ],
   "source": [
    "print(gpttoeknizer.encode(text))\n",
    "print(gpttoeknizer.encode(c_text))\n",
    "print(gpttoeknizer.encode(d_text))\n",
    "print(gpttoeknizer.encode(s_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"support/train-v1.1.json\") as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad[\"data\"][0][\"paragraphs\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"data\", \"data\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.load(\"data/train_data_qg_highlight_qg_format_t5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/train_task_data.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['qg'][1::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"qg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"qg\"][1117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train[0]['source_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(train[0]['target_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
